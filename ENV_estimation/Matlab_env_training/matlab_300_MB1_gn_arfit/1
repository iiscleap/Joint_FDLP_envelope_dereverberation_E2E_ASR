With significant advances in mobile technology as well as audio sensing devices, there is a fundamental need to describe vast amounts of audio data in terms of lower dimensional descriptors. These signal representations called features constitute the first step in processing a speech signal for various information extraction applications. The art and science of feature engineering relate to satisfying the two inherent challenges involved which are to extract sufficient information from the speech signal for the task at hand while at the same time suppress the unwanted redundancies for computational efficiency and robustness. 
The area of speech feature processing combines a wide variety of disciplines like signal processing, machine learning, psychophysics, information theory, linguistics and physiology. It has a rich history spanning more than five decades and the last few years have seen tremendous advances in these methodologies. This has propelled the transition of the speech technology from controlled environments to millions of end user applications. In this tutorial, we review the evolution of speech feature processing methods, summarize the recent advances of the last two decades and provide insights into the future of speech feature engineering. This will include the discussion on the spectral representation methods of the past, human auditory motivated techniques for robust speech processing, data driven unsupervised methods like ivectors and recent advances in deep neural network based methodologies. The future of speech signal processing will need to address various robustness issues in complex acoustic environments as well as to be able to derive useful information from big data.

